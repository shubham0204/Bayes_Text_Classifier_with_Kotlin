{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pix2Pix_ImageColorization.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyORSj35RpAGza9nca1soVpK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubham0204/Bayes_Text_Classifier_with_Kotlin/blob/master/Pix2Pix_ImageColorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH9hktX-c0Is"
      },
      "source": [
        "\r\n",
        "!unzip -q img_color_data.zip\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjMq0ZkPfCKt"
      },
      "source": [
        "\r\n",
        "import tensorflow as tf\r\n",
        "import datetime\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as6qBbiqU5WT"
      },
      "source": [
        "\r\n",
        "input_size = 256\r\n",
        "\r\n",
        "# Normalize the given images ( mean = 127.5 and std_dev = 127.6 )\r\n",
        "def normalize_images( input_image , output_image ):\r\n",
        "    normalized_input_image = ( input_image - 127.5 ) / 127.5\r\n",
        "    normalized_output_image = ( output_image - 127.5 ) / 127.5\r\n",
        "    return normalized_input_image , normalized_output_image\r\n",
        "\r\n",
        "# Resize the given images to 256 * 256\r\n",
        "def resize_images( input_image , output_image ):\r\n",
        "    resized_input_image = tf.image.resize( input_image , size=[ input_size , input_size ] )\r\n",
        "    resized_output_image = tf.image.resize( output_image , size=[ input_size , input_size ] )\r\n",
        "    return resized_input_image , resized_output_image\r\n",
        "\r\n",
        "# Load the image from the given filepath\r\n",
        "def load_image( image_filepath ):\r\n",
        "    input_image = tf.io.read_file( image_filepath )\r\n",
        "    input_image = tf.image.decode_jpeg( input_image , channels=3 )\r\n",
        "    output_image = tf.image.rgb_to_grayscale( input_image )\r\n",
        "\r\n",
        "    # resize and normalize\r\n",
        "    input_image , output_image = resize_images( input_image , output_image )\r\n",
        "    input_image , output_image = normalize_images( input_image , output_image )\r\n",
        "\r\n",
        "    return input_image , output_image\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7E5RBJhbMaz"
      },
      "source": [
        "\r\n",
        "# Directory where the images are stored\r\n",
        "master_dir = 'data'\r\n",
        "# Num examples to be included in the test dataset\r\n",
        "test_dataset_size = 50\r\n",
        "# Batch size for training the model\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "# Load the images from their filepaths\r\n",
        "dataset = tf.data.Dataset.list_files( master_dir + '/*.jpg' )\r\n",
        "dataset = dataset.map( load_image )\r\n",
        "\r\n",
        "# Splitting the dataset into train and test datasets ( See https://stackoverflow.com/questions/48213766/split-a-dataset-created-by-tensorflow-dataset-api-in-to-train-and-test )\r\n",
        "test_dataset = dataset.take( test_dataset_size )\r\n",
        "test_dataset = test_dataset.shuffle( 1000 ).batch( batch_size )\r\n",
        "\r\n",
        "train_dataset = dataset.skip( test_dataset_size )\r\n",
        "train_dataset = train_dataset.shuffle( 1000 ).batch( batch_size )\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ6y9IF8CWUz"
      },
      "source": [
        "\r\n",
        "# Downsampling block. Implements Conv -> Batch Norm ( if required ) -> LeakyReLU\r\n",
        "def block_down( x , filters , size , apply_batchnorm=True ):\r\n",
        "    x = tf.keras.layers.Conv2D( \r\n",
        "        filters , \r\n",
        "        size ,\r\n",
        "        strides=2 , \r\n",
        "        kernel_initializer=tf.random_normal_initializer( 0.0 , 0.02 ) , \r\n",
        "        padding='same',\r\n",
        "        use_bias=False) ( x )\r\n",
        "    if apply_batchnorm:\r\n",
        "        x = tf.keras.layers.BatchNormalization()( x )\r\n",
        "    x = tf.keras.layers.LeakyReLU()( x )\r\n",
        "    return x\r\n",
        "\r\n",
        "# Upsampling block. Implements Transposed Conv -> Batch Norm -> Dropout ( if required ) -> LeakyReLU\r\n",
        "def block_up( x , filters , size , apply_dropout=True ):\r\n",
        "    x = tf.keras.layers.Conv2DTranspose( \r\n",
        "        filters,\r\n",
        "        size ,\r\n",
        "        strides=2 , \r\n",
        "        kernel_initializer=tf.random_normal_initializer( 0.0 , 0.02 ) , \r\n",
        "        padding='same',\r\n",
        "        use_bias=False) ( x )\r\n",
        "    x = tf.keras.layers.BatchNormalization()( x )\r\n",
        "    if apply_dropout:\r\n",
        "        x = tf.keras.layers.Dropout( rate=0.5 )( x )\r\n",
        "    x = tf.keras.layers.ReLU()( x )\r\n",
        "    return x\r\n",
        "\r\n",
        "def get_generator():\r\n",
        "    inputs = tf.keras.layers.Input( shape=( 256 , 256 , 3 ) )\r\n",
        "\r\n",
        "    d1 = block_down( inputs , 64 , 4 , apply_batchnorm=False ) \r\n",
        "    d2 = block_down( d1 , 128 , 4 ) \r\n",
        "    d3 = block_down( d2 , 256 , 4 ) \r\n",
        "    d4 = block_down( d3 , 512 , 4 ) \r\n",
        "    d5 = block_down( d4 , 512 , 4 ) \r\n",
        "    d6 = block_down( d5 , 512 , 4 )\r\n",
        "\r\n",
        "    u1 = block_up( d6 , 512 , 4 )\r\n",
        "\r\n",
        "    concat1 = tf.keras.layers.Concatenate()( [ u1 , d5 ] )\r\n",
        "    u2 = block_up( concat1 , 512 , 4 )\r\n",
        "\r\n",
        "    concat2 = tf.keras.layers.Concatenate()( [ u2 , d4 ] )\r\n",
        "    u3 = block_up( concat2 , 512 , 4 )\r\n",
        "\r\n",
        "    concat3 = tf.keras.layers.Concatenate()( [ u3 , d3 ] )\r\n",
        "    u4 = block_up( concat3 , 256 , 4 )\r\n",
        "\r\n",
        "    concat4 = tf.keras.layers.Concatenate()( [ u4 , d2 ] )\r\n",
        "    u5 = block_up( concat4 , 128 , 4 )\r\n",
        "\r\n",
        "    outputs = tf.keras.layers.Conv2DTranspose( 3 , 4,\r\n",
        "                                         strides=2,\r\n",
        "                                         padding='same',\r\n",
        "                                         kernel_initializer=tf.random_normal_initializer(0., 0.02),\r\n",
        "                                         activation='tanh')( u5 )\r\n",
        "\r\n",
        "    return tf.keras.Model( inputs , outputs )\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo342nhw17NP"
      },
      "source": [
        "\r\n",
        "model = get_generator()\r\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVCh-izGNbJ0"
      },
      "source": [
        "\r\n",
        "def get_discriminator():\r\n",
        "  initializer = tf.random_normal_initializer(0., 0.02)\r\n",
        "\r\n",
        "  inp = tf.keras.layers.Input(shape=[256, 256, 3], name='generated_image')\r\n",
        "  tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')\r\n",
        "\r\n",
        "  x = tf.keras.layers.concatenate([inp, tar])\r\n",
        "\r\n",
        "  down1 = block_down(64, 4, False)(x)\r\n",
        "  down2 = block_down(128, 4)(down1)\r\n",
        "  down3 = block_down(256, 4)(down2)\r\n",
        "\r\n",
        "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)\r\n",
        "  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\r\n",
        "                                kernel_initializer=initializer,\r\n",
        "                                use_bias=False)(zero_pad1)\r\n",
        "\r\n",
        "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\r\n",
        "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\r\n",
        "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)\r\n",
        "  last = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2)\r\n",
        "\r\n",
        "  return tf.keras.Model(inputs=[inp, tar], outputs=last)\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3rnYLOaN4TZ"
      },
      "source": [
        "\r\n",
        "binary_crossentropy = tf.keras.losses.BinaryCrossentropy()\r\n",
        "\r\n",
        "def generator_loss( discriminator_output , generated_image , target_image ):\r\n",
        "    # Minimize -log( D( G( x ) ))\r\n",
        "    crossentropy_loss = binary_crossentropy( tf.ones_like( discriminator_output ) , discriminator_output )\r\n",
        "    # L1 Loss\r\n",
        "    l1_loss = tf.reduce_mean( tf.abs( generated_image - target_images ) ) \r\n",
        "    total loss = crossentropy_loss + ( 100 * l1_loss )\r\n",
        "    return total_loss , crossentropy_loss , total_loss\r\n",
        "\r\n",
        "def discriminator_loss( disc_real_output , disc_generated_output ):\r\n",
        "    real_image_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\r\n",
        "    generated_image_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\r\n",
        "    total_loss = real_image_loss + generated_image_loss\r\n",
        "    return total_loss\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMMqGw9LQD9n"
      },
      "source": [
        "\r\n",
        "generator_optimizer = tf.keras.optimizers.Adam( 2e-4 , beta_1=0.5 )\r\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam( 2e-4 , beta_1=0.5 )\r\n",
        "\r\n",
        "generator = get_generator()\r\n",
        "discriminator = get_discriminator()\r\n",
        "\r\n",
        "summary_writer = tf.summary.create_file_writer( \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") )\r\n",
        "\r\n",
        "@tf.function\r\n",
        "def train_step( input_image , target_image  num_epoch ):\r\n",
        "\r\n",
        "    with tf.GradientTape() as gen_tape , tf.GradientTape() as disc_tape:\r\n",
        "\r\n",
        "        generator_output = generator( input_image , training=True )\r\n",
        "\r\n",
        "        disc_real_output = discriminator( [ input_image , target_image ] , training=True )\r\n",
        "        disc_generated_output = discriminator( [ input_image , generator_output ] , training=True )\r\n",
        "\r\n",
        "        total_loss , crossentropy_loss , l1_loss = generator_loss( disc_generated_output , generated_output , target_image )\r\n",
        "        disc_loss = discriminator_loss( disc_real_output , disc_generated_output )\r\n",
        "\r\n",
        "    generator_optimizer.minimize( total_loss , variables=generator.trainable_variables )\r\n",
        "    discriminator_optimizer.minimize( disc_loss , variables=discriminator.trainable_variables )\r\n",
        "\r\n",
        "    with summary_writer.as_default():\r\n",
        "        tf.summary.scalar( 'gen_total_loss', total_loss, step=epoch )\r\n",
        "        tf.summary.scalar( 'gen_gan_loss', crossentropy_loss, step=epoch )\r\n",
        "        tf.summary.scalar( 'gen_l1_loss', l1_loss, step=epoch )\r\n",
        "        tf.summary.scalar( 'disc_loss', disc_loss, step=epoch )\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMG70uhEqjUf"
      },
      "source": [
        "\r\n",
        "for epoch in 100:\r\n",
        "    for n , ( input_images , target_images ) in train_dataset.enumerate():\r\n",
        "        train_step( input_images , target_images , n )\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}